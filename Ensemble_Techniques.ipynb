{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUKT20crKcin",
        "outputId": "112f9c94-17f4-4440-f6f9-4d0a7197c594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 features (feature : importance)\n",
            "worst perimeter : 0.1331\n",
            "worst area : 0.1281\n",
            "worst concave points : 0.1081\n",
            "mean concave points : 0.0944\n",
            "worst radius : 0.0906\n",
            "Test accuracy: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "# Q6: RandomForest on Breast Cancer - top 5 features\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "print(\"Top 5 features (feature : importance)\")\n",
        "for i in indices[:5]:\n",
        "    print(f\"{feature_names[i]} : {importances[i]:.4f}\")\n",
        "\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q7: Train a Bagging Classifier using Decision Trees on the Iris dataset and compare its accuracy with a single Decision Tree.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Single Decision Tree model\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "dt_acc = accuracy_score(y_test, dt.predict(X_test))\n",
        "print(f\"Single Decision Tree Accuracy: {dt_acc:.4f}\")\n",
        "\n",
        "# Bagging Classifier with DecisionTree base estimator\n",
        "bag = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(random_state=42),\n",
        "    n_estimators=50,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bag.fit(X_train, y_train)\n",
        "bag_acc = accuracy_score(y_test, bag.predict(X_test))\n",
        "print(f\"Bagging Classifier Accuracy: {bag_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfRrZWxfLcjX",
        "outputId": "1a7f2613-8b9f-4d5f-fd7c-742dc86e0775"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Accuracy: 0.8947\n",
            "Bagging Classifier Accuracy: 0.9211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q8: RandomForest + GridSearchCV (tune max_depth and n_estimators)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 20]\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "grid = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters:\", grid.best_params_)\n",
        "print(\"Best CV accuracy:\", grid.best_score_)\n",
        "best_model = grid.best_estimator_\n",
        "print(\"Test accuracy (best model):\", accuracy_score(y_test, best_model.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTdodIegNGEK",
        "outputId": "94bcbf21-6c82-49e0-d690-efd454e592ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': None, 'n_estimators': 200}\n",
            "Best CV accuracy: 0.9604395604395606\n",
            "Test accuracy (best model): 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q9: Train a Bagging Regressor and Random Forest Regressor on the California Housing dataset and compare their MSEs.\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# --- Load dataset ---\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# --- Split into train and test sets ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- Scale features (optional for tree models, but keeps consistency) ---\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# --- Bagging Regressor with DecisionTree base estimator ---\n",
        "bag_reg = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(random_state=42),\n",
        "    n_estimators=50,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "bag_reg.fit(X_train_s, y_train)\n",
        "y_pred_bag = bag_reg.predict(X_test_s)\n",
        "\n",
        "# --- Random Forest Regressor ---\n",
        "rf_reg = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_reg.fit(X_train_s, y_train)\n",
        "y_pred_rf = rf_reg.predict(X_test_s)\n",
        "\n",
        "# --- Compare Mean Squared Errors ---\n",
        "mse_bag = mean_squared_error(y_test, y_pred_bag)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Bagging Regressor MSE: {mse_bag:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZdn3uotNoGk",
        "outputId": "0632557c-65f4-48e5-aea3-16c8d371396f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 0.2570\n",
            "Random Forest Regressor MSE: 0.2552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10: Loan Default Prediction using Ensemble Learning\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# --- Simulated dataset (replace with real customer data) ---\n",
        "X, y = make_classification(\n",
        "    n_samples=2000, n_features=15, n_informative=8, n_redundant=2,\n",
        "    n_clusters_per_class=2, weights=[0.7, 0.3], flip_y=0.02, random_state=42\n",
        ")\n",
        "\n",
        "# --- Split data ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# --- Random Forest (Bagging) ---\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=200, max_depth=8, min_samples_leaf=5, random_state=42\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# --- Gradient Boosting (Boosting) ---\n",
        "gb = GradientBoostingClassifier(\n",
        "    n_estimators=150, learning_rate=0.1, max_depth=3, random_state=42\n",
        ")\n",
        "gb.fit(X_train, y_train)\n",
        "gb_pred = gb.predict(X_test)\n",
        "gb_auc = roc_auc_score(y_test, gb.predict_proba(X_test)[:, 1])\n",
        "\n",
        "# --- Cross-validation (5-fold) ---\n",
        "rf_cv = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
        "gb_cv = cross_val_score(gb, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
        "\n",
        "print(\"Random Forest  AUC:\", rf_auc, \"|  Mean CV:\", rf_cv.mean())\n",
        "print(\"Gradient Boost AUC:\", gb_auc, \"|  Mean CV:\", gb_cv.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX7iMeRJUdJq",
        "outputId": "61ca07f3-b668-40d9-9690-7ac4a8cfbcc5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest  AUC: 0.8869042329452888 |  Mean CV: 0.912274051130322\n",
            "Gradient Boost AUC: 0.891229005598507 |  Mean CV: 0.9087050991632379\n"
          ]
        }
      ]
    }
  ]
}